{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "machine_shape": "hm",
      "gpuType": "T4",
      "mount_file_id": "1ofEX3J-V0rVnqf3gwvTvIR1iVSGwEHZh",
      "authorship_tag": "ABX9TyP8jwiDAhSyDa8BOogIlTek",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Monson2002/IT585-Advanced_ML_Project/blob/main/Diffusion_model.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget -O sony.zip \"https://storage.googleapis.com/isl-datasets/SID/Sony.zip\""
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "SFeXQWhqYw4E",
        "outputId": "0f93e6fa-f867-4859-e63c-2872fc576516"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-05-05 18:01:55--  https://storage.googleapis.com/isl-datasets/SID/Sony.zip\n",
            "Resolving storage.googleapis.com (storage.googleapis.com)... 142.250.101.207, 142.250.141.207, 142.251.2.207, ...\n",
            "Connecting to storage.googleapis.com (storage.googleapis.com)|142.250.101.207|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 26926662016 (25G) [application/zip]\n",
            "Saving to: ‘sony.zip’\n",
            "\n",
            "sony.zip            100%[===================>]  25.08G   354MB/s    in 75s     \n",
            "\n",
            "2025-05-05 18:03:10 (342 MB/s) - ‘sony.zip’ saved [26926662016/26926662016]\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torch torchvision rawpy numpy"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "K4x3tUPPfWRM",
        "outputId": "0e8c8eb3-6437-4a8b-af9d-c786db17b866"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: torch in /usr/local/lib/python3.11/dist-packages (2.6.0+cu124)\n",
            "Requirement already satisfied: torchvision in /usr/local/lib/python3.11/dist-packages (0.21.0+cu124)\n",
            "Collecting rawpy\n",
            "  Downloading rawpy-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.2 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (2.0.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch) (3.18.0)\n",
            "Requirement already satisfied: typing-extensions>=4.10.0 in /usr/local/lib/python3.11/dist-packages (from torch) (4.13.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch) (2025.3.2)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch) (1.3.0)\n",
            "Requirement already satisfied: pillow!=8.3.*,>=5.3.0 in /usr/local/lib/python3.11/dist-packages (from torchvision) (11.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch) (3.0.2)\n",
            "Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m104.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m84.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m55.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m36.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m20.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m4.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m108.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading rawpy-0.24.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m93.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: rawpy, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, nvidia-cusparse-cu12, nvidia-cudnn-cu12, nvidia-cusolver-cu12\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "Successfully installed nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 rawpy-0.24.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zE_dzFkuPZEM",
        "outputId": "e4e51d97-e21d-42c4-a71c-b507753cf1a1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# # The following code will only execute\n",
        "# # successfully when compression is complete\n",
        "\n",
        "# import kagglehub\n",
        "\n",
        "# # Download latest version\n",
        "# path = kagglehub.dataset_download(\"monsonrejiverghese/aml-sld\")\n",
        "\n",
        "# print(\"Path to dataset files:\", path)"
      ],
      "metadata": {
        "id": "r0ZJEL8hik25"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install -q kaggle\n",
        "!mkdir -p ~/.kaggle\n",
        "!cp kaggle.json ~/.kaggle/\n",
        "!chmod 600 ~/.kaggle/kaggle.json"
      ],
      "metadata": {
        "id": "0J5fiem3jUHZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!kaggle datasets download -d monsonrejiverghese/aml-sld\n",
        "# Example: !kaggle datasets download -d zynicide/wine-reviews"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7E60pkcvj0DN",
        "outputId": "1f77d61c-4dfb-44fb-fb8b-50e013e45faf"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Dataset URL: https://www.kaggle.com/datasets/monsonrejiverghese/aml-sld\n",
            "License(s): Community Data License Agreement - Permissive - Version 1.0\n",
            "404 Client Error: Not Found for url: https://www.kaggle.com/api/v1/datasets/download/monsonrejiverghese/aml-sld?raw=false\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rawpy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "from torchvision import transforms, models\n",
        "import random\n",
        "from torch.amp import GradScaler, autocast\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "import io\n",
        "\n",
        "# Mount Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Set PyTorch CUDA memory management to reduce fragmentation\n",
        "os.environ[\"PYTORCH_CUDA_ALLOC_CONF\"] = \"expandable_segments:True\"\n",
        "\n",
        "# Clear GPU memory\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Extract SID dataset from Google Drive without saving zip locally\n",
        "def extract_zip_from_drive(zip_path, extract_to):\n",
        "    with zipfile.ZipFile(zip_path, 'r') as zip_ref:\n",
        "        zip_ref.extractall(extract_to)\n",
        "    print(f\"Extracted dataset to {extract_to}\")\n",
        "\n",
        "zip_path = '/content/drive/MyDrive/Sony.zip'  # Adjust path as needed\n",
        "extract_to = '/content/aml-sld'\n",
        "os.makedirs(extract_to, exist_ok=True)\n",
        "extract_zip_from_drive(zip_path, extract_to)\n",
        "\n",
        "# Custom Dataset for SID (×100 amplification only)\n",
        "class SIDDataset(Dataset):\n",
        "    def __init__(self, txt_file, data_root='/content/aml-sld', patch_size=256, target_amplification=100, is_train=True):\n",
        "        self.data_root = data_root\n",
        "        self.patch_size = patch_size\n",
        "        self.target_amplification = target_amplification\n",
        "        self.is_train = is_train\n",
        "        self.pairs = []\n",
        "\n",
        "        # Load pairs from the .txt file\n",
        "        with open(txt_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                short_path, long_path, iso, fstop = line.strip().split()\n",
        "                short_exp = float(short_path.split('_')[-1].replace('s.ARW', ''))\n",
        "                long_exp = float(long_path.split('_')[-1].replace('s.ARW', ''))\n",
        "                if short_exp > 0:\n",
        "                    amplification = long_exp / short_exp\n",
        "                    if 90 <= amplification <= 110:\n",
        "                        self.pairs.append((short_path, long_path, short_exp, long_exp))\n",
        "\n",
        "        # Split into train and test (90% train, 10% test)\n",
        "        self.pairs = sorted(self.pairs, key=lambda x: x[0])\n",
        "        split_idx = int(0.9 * len(self.pairs))\n",
        "        if is_train:\n",
        "            self.pairs = self.pairs[:split_idx]\n",
        "        else:\n",
        "            self.pairs = self.pairs[split_idx:]\n",
        "\n",
        "        # If training, oversample ×100 pairs\n",
        "        if self.is_train:\n",
        "            x100_pairs = self.pairs[:]\n",
        "            while len(self.pairs) < 1000:\n",
        "                self.pairs.extend(random.choices(x100_pairs, k=len(x100_pairs)))\n",
        "\n",
        "        print(f\"{'Training' if is_train else 'Testing'} dataset: Found {len(self.pairs)} pairs with amplification ratio ~{target_amplification}\")\n",
        "\n",
        "        self.transform = transforms.Compose([\n",
        "            transforms.RandomHorizontalFlip(p=0.5),\n",
        "            transforms.RandomVerticalFlip(p=0.5),\n",
        "            transforms.RandomRotation(degrees=90),\n",
        "        ]) if is_train else None\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        short_path, long_path, short_exp, long_exp = self.pairs[idx]\n",
        "\n",
        "        # Load raw images\n",
        "        short_raw = rawpy.imread(os.path.join(self.data_root, short_path))\n",
        "        long_raw = rawpy.imread(os.path.join(self.data_root, long_path))\n",
        "\n",
        "        short_bayer = short_raw.raw_image_visible.astype(np.float32) - 512\n",
        "        long_bayer = long_raw.raw_image_visible.astype(np.float32) - 512\n",
        "\n",
        "        short_bayer = np.clip(short_bayer / (4095 - 512), 0, 1)\n",
        "        long_bayer = np.clip(long_bayer / (4095 - 512), 0, 1)\n",
        "\n",
        "        h, w = short_bayer.shape\n",
        "        short_packed = np.zeros((h//2, w//2, 4), dtype=np.float32)\n",
        "        long_packed = np.zeros((h//2, w//2, 4), dtype=np.float32)\n",
        "\n",
        "        short_packed[..., 0] = short_bayer[0::2, 0::2]\n",
        "        short_packed[..., 1] = short_bayer[0::2, 1::2]\n",
        "        short_packed[..., 2] = short_bayer[1::2, 0::2]\n",
        "        short_packed[..., 3] = short_bayer[1::2, 1::2]\n",
        "        long_packed[..., 0] = long_bayer[0::2, 0::2]\n",
        "        long_packed[..., 1] = long_bayer[0::2, 1::2]\n",
        "        long_packed[..., 2] = long_bayer[1::2, 0::2]\n",
        "        long_packed[..., 3] = long_bayer[1::2, 1::2]\n",
        "\n",
        "        h, w, _ = short_packed.shape\n",
        "        if self.is_train:\n",
        "            i = np.random.randint(0, h - self.patch_size + 1)\n",
        "            j = np.random.randint(0, w - self.patch_size + 1)\n",
        "        else:\n",
        "            i = (h - self.patch_size) // 2\n",
        "            j = (w - self.patch_size) // 2\n",
        "        short_patch = short_packed[i:i+self.patch_size, j:j+self.patch_size, :]\n",
        "        long_patch = long_packed[i:i+self.patch_size, j:j+self.patch_size, :]\n",
        "\n",
        "        short_patch = torch.from_numpy(short_patch).permute(2, 0, 1)\n",
        "        long_patch = torch.from_numpy(long_patch).permute(2, 0, 1)\n",
        "\n",
        "        if self.transform:\n",
        "            stacked = torch.stack([short_patch, long_patch], dim=0)\n",
        "            stacked = self.transform(stacked)\n",
        "            short_patch, long_patch = stacked[0], stacked[1]\n",
        "\n",
        "        return short_patch, long_patch, short_exp, long_exp\n",
        "\n",
        "# Perceptual Loss using VGG16\n",
        "class PerceptualLoss(nn.Module):\n",
        "    def __init__(self, device):\n",
        "        super(PerceptualLoss, self).__init__()\n",
        "        vgg = models.vgg16(weights=models.VGG16_Weights.IMAGENET1K_V1).features[:16].eval().to(device)\n",
        "        for param in vgg.parameters():\n",
        "            param.requires_grad = False\n",
        "        self.vgg = vgg\n",
        "        self.criterion = nn.MSELoss()\n",
        "\n",
        "    def forward(self, x, y):\n",
        "        x_rgb = x[:, :3, :, :].mean(dim=1, keepdim=True).repeat(1, 3, 1, 1)\n",
        "        y_rgb = y[:, :3, :, :].mean(dim=1, keepdim=True).repeat(1, 3, 1, 1)\n",
        "        x_vgg = self.vgg(x_rgb)\n",
        "        y_vgg = self.vgg(y_rgb)\n",
        "        return self.criterion(x_vgg, y_vgg)\n",
        "\n",
        "# NAFNet Architecture\n",
        "class SimpleGate(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(SimpleGate, self).__init__()\n",
        "\n",
        "    def forward(self, x):\n",
        "        x1, x2 = x.chunk(2, dim=1)\n",
        "        return x1 * x2\n",
        "\n",
        "class SimplifiedChannelAttention(nn.Module):\n",
        "    def __init__(self, channel):\n",
        "        super(SimplifiedChannelAttention, self).__init__()\n",
        "        self.avg_pool = nn.AdaptiveAvgPool2d(1)\n",
        "        self.conv = nn.Conv2d(channel, channel, 1, bias=True)\n",
        "        self.sigmoid = nn.Sigmoid()\n",
        "\n",
        "    def forward(self, x):\n",
        "        y = self.avg_pool(x)\n",
        "        y = self.conv(y)\n",
        "        y = self.sigmoid(y)\n",
        "        return x * y\n",
        "\n",
        "class NAFBlock(nn.Module):\n",
        "    def __init__(self, c, drop_path_rate=0.0):\n",
        "        super(NAFBlock, self).__init__()\n",
        "        self.conv1 = nn.Conv2d(c, c, 3, padding=1)\n",
        "        self.conv2 = nn.Conv2d(c, c * 2, 3, padding=1)\n",
        "        self.conv3 = nn.Conv2d(c, c, 3, padding=1)\n",
        "        self.norm1 = nn.LayerNorm(c)\n",
        "        self.norm2 = nn.LayerNorm(c * 2)\n",
        "        self.sca = SimplifiedChannelAttention(c)\n",
        "        self.sg = SimpleGate()\n",
        "        self.drop_path = nn.Identity() if drop_path_rate == 0.0 else nn.Dropout(drop_path_rate)\n",
        "\n",
        "        nn.init.kaiming_normal_(self.conv1.weight, mode='fan_in', nonlinearity='relu')\n",
        "        nn.init.kaiming_normal_(self.conv2.weight, mode='fan_in', nonlinearity='relu')\n",
        "        nn.init.kaiming_normal_(self.conv3.weight, mode='fan_in', nonlinearity='relu')\n",
        "        if self.conv1.bias is not None:\n",
        "            nn.init.constant_(self.conv1.bias, 0)\n",
        "        if self.conv2.bias is not None:\n",
        "            nn.init.constant_(self.conv2.bias, 0)\n",
        "        if self.conv3.bias is not None:\n",
        "            nn.init.constant_(self.conv3.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        residual = x\n",
        "        x = self.norm1(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "        x = self.conv1(x)\n",
        "        x = self.sca(x)\n",
        "        x = self.conv2(x)\n",
        "        x = self.norm2(x.permute(0, 2, 3, 1)).permute(0, 3, 1, 2)\n",
        "        x = self.sg(x)\n",
        "        x = self.conv3(x)\n",
        "        x = self.drop_path(x) + residual\n",
        "        return x\n",
        "\n",
        "class NAFNet(nn.Module):\n",
        "    def __init__(self, in_channels=4, out_channels=4, width=32, enc_blocks=[2, 2, 2, 2], dec_blocks=[2, 2, 2, 2], middle_blocks=2, drop_path_rate=0.0):\n",
        "        super(NAFNet, self).__init__()\n",
        "        self.width = width\n",
        "\n",
        "        self.conv_in = nn.Conv2d(in_channels, width, 3, padding=1)\n",
        "\n",
        "        self.enc1 = nn.ModuleList([NAFBlock(width, drop_path_rate) for _ in range(enc_blocks[0])])\n",
        "        self.down1 = nn.Conv2d(width, width * 2, 3, stride=2, padding=1)\n",
        "        self.enc2 = nn.ModuleList([NAFBlock(width * 2, drop_path_rate) for _ in range(enc_blocks[1])])\n",
        "        self.down2 = nn.Conv2d(width * 2, width * 4, 3, stride=2, padding=1)\n",
        "        self.enc3 = nn.ModuleList([NAFBlock(width * 4, drop_path_rate) for _ in range(enc_blocks[2])])\n",
        "        self.down3 = nn.Conv2d(width * 4, width * 8, 3, stride=2, padding=1)\n",
        "        self.enc4 = nn.ModuleList([NAFBlock(width * 8, drop_path_rate) for _ in range(enc_blocks[3])])\n",
        "        self.down4 = nn.Conv2d(width * 8, width * 16, 3, stride=2, padding=1)\n",
        "\n",
        "        self.middle = nn.ModuleList([NAFBlock(width * 16, drop_path_rate) for _ in range(middle_blocks)])\n",
        "\n",
        "        self.up1 = nn.ConvTranspose2d(width * 16, width * 8, 4, stride=2, padding=1)\n",
        "        self.dec1 = nn.ModuleList([NAFBlock(width * 8, drop_path_rate) for _ in range(dec_blocks[0])])\n",
        "        self.up2 = nn.ConvTranspose2d(width * 8, width * 4, 4, stride=2, padding=1)\n",
        "        self.dec2 = nn.ModuleList([NAFBlock(width * 4, drop_path_rate) for _ in range(dec_blocks[1])])\n",
        "        self.up3 = nn.ConvTranspose2d(width * 4, width * 2, 4, stride=2, padding=1)\n",
        "        self.dec3 = nn.ModuleList([NAFBlock(width * 2, drop_path_rate) for _ in range(dec_blocks[2])])\n",
        "        self.up4 = nn.ConvTranspose2d(width * 2, width, 4, stride=2, padding=1)\n",
        "        self.dec4 = nn.ModuleList([NAFBlock(width, drop_path_rate) for _ in range(dec_blocks[3])])\n",
        "\n",
        "        self.conv_out = nn.Conv2d(width, out_channels, 3, padding=1)\n",
        "\n",
        "        nn.init.kaiming_normal_(self.conv_in.weight, mode='fan_in', nonlinearity='relu')\n",
        "        nn.init.kaiming_normal_(self.conv_out.weight, mode='fan_in', nonlinearity='relu')\n",
        "        if self.conv_in.bias is not None:\n",
        "            nn.init.constant_(self.conv_in.bias, 0)\n",
        "        if self.conv_out.bias is not None:\n",
        "            nn.init.constant_(self.conv_out.bias, 0)\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.conv_in(x)\n",
        "        e1 = x\n",
        "        for block in self.enc1:\n",
        "            e1 = block(e1)\n",
        "        e2 = self.down1(e1)\n",
        "        for block in self.enc2:\n",
        "            e2 = block(e2)\n",
        "        e3 = self.down2(e2)\n",
        "        for block in self.enc3:\n",
        "            e3 = block(e3)\n",
        "        e4 = self.down3(e3)\n",
        "        for block in self.enc4:\n",
        "            e4 = block(e4)\n",
        "        m = self.down4(e4)\n",
        "        for block in self.middle:\n",
        "            m = block(m)\n",
        "        d1 = self.up1(m)\n",
        "        d1 = d1 + e4\n",
        "        for block in self.dec1:\n",
        "            d1 = block(d1)\n",
        "        d2 = self.up2(d1)\n",
        "        d2 = d2 + e3\n",
        "        for block in self.dec2:\n",
        "            d2 = block(d2)\n",
        "        d3 = self.up3(d2)\n",
        "        d3 = d3 + e2\n",
        "        for block in self.dec3:\n",
        "            d3 = block(d3)\n",
        "        d4 = self.up4(d3)\n",
        "        d4 = d4 + e1\n",
        "        for block in self.dec4:\n",
        "            d4 = block(d4)\n",
        "        out = self.conv_out(d4)\n",
        "        return out\n",
        "\n",
        "# Diffusion Model Training Function\n",
        "def train_diffusion_model():\n",
        "    data_root = \"/content/aml-sld\"\n",
        "    train_txt = os.path.join(data_root, \"Sony_train_list.txt\")\n",
        "\n",
        "    train_dataset = SIDDataset(train_txt, data_root=data_root, patch_size=256, target_amplification=100, is_train=True)\n",
        "    train_loader = DataLoader(train_dataset, batch_size=1, shuffle=True, num_workers=2, pin_memory=True)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"GPU not available\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    model = NAFNet(in_channels=4, out_channels=4, width=32, enc_blocks=[2, 2, 2, 2], dec_blocks=[2, 2, 2, 2], middle_blocks=2, drop_path_rate=0.0).to(device)\n",
        "    criterion_l1 = nn.L1Loss()\n",
        "    criterion_perceptual = PerceptualLoss(device)\n",
        "    optimizer = optim.AdamW(model.parameters(), lr=5e-4, weight_decay=1e-4)\n",
        "    scheduler = optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=100)\n",
        "    scaler = GradScaler('cuda')\n",
        "\n",
        "    # Diffusion parameters\n",
        "    num_timesteps = 1000\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    betas = torch.linspace(beta_start, beta_end, num_timesteps, device=device)\n",
        "    alphas = 1.0 - betas\n",
        "    alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
        "    sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "    sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
        "\n",
        "    num_epochs = 100\n",
        "    accum_steps = 8\n",
        "\n",
        "    print(\"Starting diffusion model training...\")\n",
        "    for epoch in range(num_epochs):\n",
        "        model.train()\n",
        "        running_loss = 0.0\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        for i, (short_img, long_img, _, _) in enumerate(train_loader):\n",
        "            short_img = short_img.to(device, non_blocking=True)\n",
        "            long_img = long_img.to(device, non_blocking=True)\n",
        "\n",
        "            # Sample random timesteps\n",
        "            t = torch.randint(0, num_timesteps, (short_img.size(0),), device=device)\n",
        "\n",
        "            # Add Gaussian noise\n",
        "            noise = torch.randn_like(long_img)\n",
        "            sqrt_alpha_t = sqrt_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
        "            sqrt_one_minus_alpha_t = sqrt_one_minus_alphas_cumprod[t].view(-1, 1, 1, 1)\n",
        "            noisy_img = sqrt_alpha_t * long_img + sqrt_one_minus_alpha_t * noise\n",
        "\n",
        "            with autocast('cuda'):\n",
        "                predicted_noise = model(noisy_img)\n",
        "                loss_l1 = criterion_l1(predicted_noise, noise)\n",
        "                loss_perceptual = criterion_perceptual(predicted_noise, noise)\n",
        "                loss = 0.9 * loss_l1 + 0.1 * loss_perceptual\n",
        "                loss = loss / accum_steps\n",
        "\n",
        "            running_loss += loss.item() * accum_steps\n",
        "\n",
        "            scaler.scale(loss).backward()\n",
        "\n",
        "            if (i + 1) % accum_steps == 0 or (i + 1) == len(train_loader):\n",
        "                torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n",
        "                scaler.step(optimizer)\n",
        "                scaler.update()\n",
        "                optimizer.zero_grad()\n",
        "\n",
        "        scheduler.step()\n",
        "        avg_loss = running_loss / len(train_loader)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], Loss: {avg_loss:.4f}\")\n",
        "\n",
        "        torch.cuda.empty_cache()\n",
        "\n",
        "    torch.save(model.state_dict(), \"/content/diffusion_model.pth\")\n",
        "    print(\"Training completed and model saved.\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    train_diffusion_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TeEGgpDrZvPK",
        "outputId": "b7d49317-af9b-4d3b-f35b-26f81b714033"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n",
            "Extracted dataset to /content/aml-sld\n",
            "Training dataset: Found 1056 pairs with amplification ratio ~100\n",
            "Using device: cuda:0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "Downloading: \"https://download.pytorch.org/models/vgg16-397923af.pth\" to /root/.cache/torch/hub/checkpoints/vgg16-397923af.pth\n",
            "100%|██████████| 528M/528M [00:03<00:00, 160MB/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Starting diffusion model training...\n",
            "Epoch [1/100], Loss: 1.7574\n",
            "Epoch [2/100], Loss: 0.4736\n",
            "Epoch [3/100], Loss: 0.2997\n",
            "Epoch [4/100], Loss: 0.2551\n",
            "Epoch [5/100], Loss: 0.2389\n",
            "Epoch [6/100], Loss: 0.2226\n",
            "Epoch [7/100], Loss: 0.2165\n",
            "Epoch [8/100], Loss: 0.2156\n",
            "Epoch [9/100], Loss: 0.2253\n",
            "Epoch [10/100], Loss: 0.2044\n",
            "Epoch [11/100], Loss: 0.2018\n",
            "Epoch [12/100], Loss: 0.1900\n",
            "Epoch [13/100], Loss: 0.1825\n",
            "Epoch [14/100], Loss: 0.1740\n",
            "Epoch [15/100], Loss: 0.1727\n",
            "Epoch [16/100], Loss: 0.1611\n",
            "Epoch [17/100], Loss: 0.1489\n",
            "Epoch [18/100], Loss: 0.1434\n",
            "Epoch [19/100], Loss: 0.1293\n",
            "Epoch [20/100], Loss: 0.1269\n",
            "Epoch [21/100], Loss: 0.1273\n",
            "Epoch [22/100], Loss: 0.1188\n",
            "Epoch [23/100], Loss: 0.1259\n",
            "Epoch [24/100], Loss: 0.1122\n",
            "Epoch [25/100], Loss: 0.1283\n",
            "Epoch [26/100], Loss: 0.1239\n",
            "Epoch [27/100], Loss: 0.1135\n",
            "Epoch [28/100], Loss: 0.1114\n",
            "Epoch [29/100], Loss: 0.1121\n",
            "Epoch [30/100], Loss: 0.1101\n",
            "Epoch [31/100], Loss: 0.1056\n",
            "Epoch [32/100], Loss: 0.1054\n",
            "Epoch [33/100], Loss: 0.1171\n",
            "Epoch [34/100], Loss: 0.1316\n",
            "Epoch [35/100], Loss: 0.1056\n",
            "Epoch [36/100], Loss: 0.1011\n",
            "Epoch [37/100], Loss: 0.0992\n",
            "Epoch [38/100], Loss: 0.0876\n",
            "Epoch [39/100], Loss: 0.0861\n",
            "Epoch [40/100], Loss: 0.0839\n",
            "Epoch [41/100], Loss: 0.0840\n",
            "Epoch [42/100], Loss: 0.0865\n",
            "Epoch [43/100], Loss: 0.0732\n",
            "Epoch [44/100], Loss: 0.0814\n",
            "Epoch [45/100], Loss: 0.0785\n",
            "Epoch [46/100], Loss: 0.0765\n",
            "Epoch [47/100], Loss: 0.0727\n",
            "Epoch [48/100], Loss: 0.0696\n",
            "Epoch [49/100], Loss: 0.0691\n",
            "Epoch [50/100], Loss: 0.0626\n",
            "Epoch [51/100], Loss: 0.0723\n",
            "Epoch [52/100], Loss: 0.0547\n",
            "Epoch [53/100], Loss: 0.0685\n",
            "Epoch [54/100], Loss: 0.0599\n",
            "Epoch [55/100], Loss: 0.0567\n",
            "Epoch [56/100], Loss: 0.0552\n",
            "Epoch [57/100], Loss: 0.0543\n",
            "Epoch [58/100], Loss: 0.0569\n",
            "Epoch [59/100], Loss: 0.0573\n",
            "Epoch [60/100], Loss: 0.0503\n",
            "Epoch [61/100], Loss: 0.0543\n",
            "Epoch [62/100], Loss: 0.0499\n",
            "Epoch [63/100], Loss: 0.0505\n",
            "Epoch [64/100], Loss: 0.0476\n",
            "Epoch [65/100], Loss: 0.0523\n",
            "Epoch [66/100], Loss: 0.0504\n",
            "Epoch [67/100], Loss: 0.0524\n",
            "Epoch [68/100], Loss: 0.0463\n",
            "Epoch [69/100], Loss: 0.0486\n",
            "Epoch [70/100], Loss: 0.0446\n",
            "Epoch [71/100], Loss: 0.0468\n",
            "Epoch [72/100], Loss: 0.0480\n",
            "Epoch [73/100], Loss: 0.0463\n",
            "Epoch [74/100], Loss: 0.0479\n",
            "Epoch [75/100], Loss: 0.0505\n",
            "Epoch [76/100], Loss: 0.0527\n",
            "Epoch [77/100], Loss: 0.0474\n",
            "Epoch [78/100], Loss: 0.0481\n",
            "Epoch [79/100], Loss: 0.0449\n",
            "Epoch [80/100], Loss: 0.0482\n",
            "Epoch [81/100], Loss: 0.0505\n",
            "Epoch [82/100], Loss: 0.0438\n",
            "Epoch [83/100], Loss: 0.0491\n",
            "Epoch [84/100], Loss: 0.0475\n",
            "Epoch [85/100], Loss: 0.0459\n",
            "Epoch [86/100], Loss: 0.0402\n",
            "Epoch [87/100], Loss: 0.0476\n",
            "Epoch [88/100], Loss: 0.0468\n",
            "Epoch [89/100], Loss: 0.0435\n",
            "Epoch [90/100], Loss: 0.0432\n",
            "Epoch [91/100], Loss: 0.0491\n",
            "Epoch [92/100], Loss: 0.0410\n",
            "Epoch [93/100], Loss: 0.0471\n",
            "Epoch [94/100], Loss: 0.0429\n",
            "Epoch [95/100], Loss: 0.0454\n",
            "Epoch [96/100], Loss: 0.0430\n",
            "Epoch [97/100], Loss: 0.0420\n",
            "Epoch [98/100], Loss: 0.0464\n",
            "Epoch [99/100], Loss: 0.0449\n",
            "Epoch [100/100], Loss: 0.0422\n",
            "Training completed and model saved.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install torchmetrics"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4qkFo9cjSqol",
        "outputId": "c8fe2177-8a1b-4c8f-c52e-c93b7592e77b"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchmetrics\n",
            "  Downloading torchmetrics-1.7.1-py3-none-any.whl.metadata (21 kB)\n",
            "Requirement already satisfied: numpy>1.20.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.0.2)\n",
            "Requirement already satisfied: packaging>17.1 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (24.2)\n",
            "Requirement already satisfied: torch>=2.0.0 in /usr/local/lib/python3.11/dist-packages (from torchmetrics) (2.6.0+cu124)\n",
            "Collecting lightning-utilities>=0.8.0 (from torchmetrics)\n",
            "  Downloading lightning_utilities-0.14.3-py3-none-any.whl.metadata (5.6 kB)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (75.2.0)\n",
            "Requirement already satisfied: typing_extensions in /usr/local/lib/python3.11/dist-packages (from lightning-utilities>=0.8.0->torchmetrics) (4.13.2)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.18.0)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.1.6)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2025.3.2)\n",
            "Requirement already satisfied: nvidia-cuda-nvrtc-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-runtime-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cuda-cupti-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-cudnn-cu12==9.1.0.70 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (9.1.0.70)\n",
            "Requirement already satisfied: nvidia-cublas-cu12==12.4.5.8 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.5.8)\n",
            "Requirement already satisfied: nvidia-cufft-cu12==11.2.1.3 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.2.1.3)\n",
            "Requirement already satisfied: nvidia-curand-cu12==10.3.5.147 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (10.3.5.147)\n",
            "Requirement already satisfied: nvidia-cusolver-cu12==11.6.1.9 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (11.6.1.9)\n",
            "Requirement already satisfied: nvidia-cusparse-cu12==12.3.1.170 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.3.1.170)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: nvidia-nvjitlink-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (12.4.127)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2.0.0->torchmetrics) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2.0.0->torchmetrics) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2.0.0->torchmetrics) (3.0.2)\n",
            "Downloading torchmetrics-1.7.1-py3-none-any.whl (961 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m961.5/961.5 kB\u001b[0m \u001b[31m14.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading lightning_utilities-0.14.3-py3-none-any.whl (28 kB)\n",
            "Installing collected packages: lightning-utilities, torchmetrics\n",
            "Successfully installed lightning-utilities-0.14.3 torchmetrics-1.7.1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rawpy\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchmetrics\n",
        "from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
        "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity\n",
        "from google.colab import drive\n",
        "import zipfile\n",
        "\n",
        "# Test Function for Diffusion Model\n",
        "def test_diffusion_model():\n",
        "    data_root = \"/content/aml-sld\"\n",
        "    test_txt = os.path.join(data_root, \"Sony_test_list.txt\")\n",
        "    output_file = \"/content/diffusion_test_results.txt\"\n",
        "\n",
        "    test_dataset = SIDDataset(test_txt, data_root=data_root, patch_size=256, target_amplification=100)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"GPU not available\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    model = NAFNet(in_channels=4, out_channels=4, width=32, enc_blocks=[2, 2, 2, 2], dec_blocks=[2, 2, 2, 2], middle_blocks=2, drop_path_rate=0.0).to(device)\n",
        "    model.load_state_dict(torch.load(\"/content/diffusion_model.pth\", weights_only=True))\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize metrics\n",
        "    psnr_metric = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
        "    ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
        "    lpips_metric = LearnedPerceptualImagePatchSimilarity(net_type='vgg', normalize=True).to(device)\n",
        "\n",
        "    # Diffusion parameters (reduced to 20 timesteps)\n",
        "    num_timesteps = 20\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    betas = torch.linspace(beta_start, beta_end, num_timesteps, device=device)\n",
        "    alphas = 1.0 - betas\n",
        "    alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
        "    sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "    sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
        "    alpha_bar_t = alphas_cumprod\n",
        "    one_minus_alpha_bar_t = 1.0 - alphas_cumprod\n",
        "    sqrt_one_minus_alpha_bar_t = torch.sqrt(one_minus_alpha_bar_t)\n",
        "\n",
        "    total_psnr, total_ssim, total_lpips = 0.0, 0.0, 0.0\n",
        "    num_samples = 0\n",
        "\n",
        "    # Open text file to save results\n",
        "    with open(output_file, 'w') as f:\n",
        "        f.write(\"Diffusion Model Test Results\\n\")\n",
        "        f.write(\"Sample | PSNR | SSIM | LPIPS\\n\")\n",
        "        f.write(\"-\" * 40 + \"\\n\")\n",
        "\n",
        "        print(\"Starting diffusion model testing...\")\n",
        "        with torch.no_grad():\n",
        "            for i, (short_img, long_img, _, _) in enumerate(test_loader):\n",
        "                short_img = short_img.to(device, non_blocking=True)\n",
        "                long_img = long_img.to(device, non_blocking=True)\n",
        "\n",
        "                # Initialize with pure noise (simulate x_T)\n",
        "                x_t = torch.randn_like(long_img)\n",
        "\n",
        "                # Reverse diffusion process\n",
        "                for t in range(num_timesteps - 1, -1, -1):\n",
        "                    t_tensor = torch.full((1,), t, device=device, dtype=torch.long)\n",
        "\n",
        "                    # Predict noise\n",
        "                    predicted_noise = model(x_t)\n",
        "\n",
        "                    # Compute coefficients\n",
        "                    alpha_t = alphas[t]\n",
        "                    alpha_bar_t_val = alpha_bar_t[t]\n",
        "                    sqrt_one_minus_alpha_bar_t_val = sqrt_one_minus_alpha_bar_t[t]\n",
        "\n",
        "                    # Denoise step\n",
        "                    noise = torch.randn_like(x_t) if t > 0 else torch.zeros_like(x_t)\n",
        "                    x_t = (1.0 / torch.sqrt(alpha_t)) * (x_t - ((1 - alpha_t) / sqrt_one_minus_alpha_bar_t_val) * predicted_noise) + torch.sqrt(1 - alpha_t) * noise\n",
        "                    x_t = torch.clamp(x_t, 0, 1)\n",
        "\n",
        "                # Final denoised image\n",
        "                pred_x0 = x_t\n",
        "\n",
        "                # Convert to RGB-like for LPIPS\n",
        "                pred_x0_rgb = bayer_to_rgb(pred_x0)\n",
        "                long_img_rgb = bayer_to_rgb(long_img)\n",
        "\n",
        "                # Compute metrics\n",
        "                psnr = psnr_metric(pred_x0, long_img)\n",
        "                ssim = ssim_metric(pred_x0, long_img)\n",
        "                lpips = lpips_metric(pred_x0_rgb, long_img_rgb)\n",
        "\n",
        "                total_psnr += psnr.item()\n",
        "                total_ssim += ssim.item()\n",
        "                total_lpips += lpips.item()\n",
        "                num_samples += 1\n",
        "\n",
        "                # Write per-sample metrics to file and print\n",
        "                result_line = f\"{i+1:03d} | {psnr.item():.4f} | {ssim.item():.4f} | {lpips.item():.4f}\\n\"\n",
        "                f.write(result_line)\n",
        "                print(f\"Sample [{i+1}/{len(test_loader)}], PSNR: {psnr:.4f}, SSIM: {ssim:.4f}, LPIPS: {lpips:.4f}\")\n",
        "\n",
        "        # Compute and write average metrics\n",
        "        avg_psnr = total_psnr / num_samples\n",
        "        avg_ssim = total_ssim / num_samples\n",
        "        avg_lpips = total_lpips / num_samples\n",
        "\n",
        "        f.write(\"-\" * 40 + \"\\n\")\n",
        "        f.write(f\"Average PSNR: {avg_psnr:.4f}\\n\")\n",
        "        f.write(f\"Average SSIM: {avg_ssim:.4f}\\n\")\n",
        "        f.write(f\"Average LPIPS: {avg_lpips:.4f}\\n\")\n",
        "\n",
        "    print(f\"\\nTest Results saved to {output_file}:\")\n",
        "    print(f\"Average PSNR: {avg_psnr:.4f}\")\n",
        "    print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
        "    print(f\"Average LPIPS: {avg_lpips:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_diffusion_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "9lSoKjJ9Skvk",
        "outputId": "93df6a79-ec11-4068-bdfc-dac7061a2a1f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Training dataset: Found 1141 pairs with amplification ratio ~100\n",
            "Using device: cuda:0\n",
            "Starting diffusion model testing...\n",
            "Sample [1/1141], PSNR: 10.8590, SSIM: 0.0964, LPIPS: 0.7473\n",
            "Sample [2/1141], PSNR: 9.4116, SSIM: 0.0522, LPIPS: 0.7390\n",
            "Sample [3/1141], PSNR: 11.0093, SSIM: 0.0929, LPIPS: 0.7423\n",
            "Sample [4/1141], PSNR: 8.9169, SSIM: 0.0280, LPIPS: 0.7824\n",
            "Sample [5/1141], PSNR: 9.5660, SSIM: 0.0542, LPIPS: 0.7282\n",
            "Sample [6/1141], PSNR: 8.9662, SSIM: 0.0310, LPIPS: 0.7749\n",
            "Sample [7/1141], PSNR: 9.7783, SSIM: 0.0533, LPIPS: 0.7428\n",
            "Sample [8/1141], PSNR: 9.1156, SSIM: 0.0350, LPIPS: 0.7763\n",
            "Sample [9/1141], PSNR: 10.4303, SSIM: 0.0773, LPIPS: 0.7375\n",
            "Sample [10/1141], PSNR: 11.5059, SSIM: 0.0781, LPIPS: 0.7426\n",
            "Sample [11/1141], PSNR: 12.4158, SSIM: 0.1602, LPIPS: 0.7238\n",
            "Sample [12/1141], PSNR: 10.7593, SSIM: 0.1140, LPIPS: 0.7843\n",
            "Sample [13/1141], PSNR: 10.5527, SSIM: 0.0991, LPIPS: 0.7500\n",
            "Sample [14/1141], PSNR: 9.7275, SSIM: 0.0646, LPIPS: 0.7566\n",
            "Sample [15/1141], PSNR: 11.6017, SSIM: 0.1364, LPIPS: 0.7307\n",
            "Sample [16/1141], PSNR: 9.0760, SSIM: 0.0371, LPIPS: 0.7399\n",
            "Sample [17/1141], PSNR: 11.0870, SSIM: 0.1103, LPIPS: 0.7458\n",
            "Sample [18/1141], PSNR: 9.1287, SSIM: 0.0337, LPIPS: 0.7720\n",
            "Sample [19/1141], PSNR: 10.4233, SSIM: 0.0916, LPIPS: 0.7471\n",
            "Sample [20/1141], PSNR: 11.7307, SSIM: 0.1428, LPIPS: 0.7366\n",
            "Sample [21/1141], PSNR: 10.4961, SSIM: 0.1049, LPIPS: 0.7543\n",
            "Sample [22/1141], PSNR: 10.6691, SSIM: 0.1015, LPIPS: 0.7521\n",
            "Sample [23/1141], PSNR: 10.1132, SSIM: 0.0920, LPIPS: 0.7150\n",
            "Sample [24/1141], PSNR: 10.6651, SSIM: 0.1094, LPIPS: 0.7764\n",
            "Sample [25/1141], PSNR: 10.9780, SSIM: 0.1217, LPIPS: 0.7516\n",
            "Sample [26/1141], PSNR: 11.2542, SSIM: 0.1275, LPIPS: 0.7415\n",
            "Sample [27/1141], PSNR: 10.8259, SSIM: 0.1195, LPIPS: 0.7626\n",
            "Sample [28/1141], PSNR: 10.5148, SSIM: 0.1050, LPIPS: 0.7417\n",
            "Sample [29/1141], PSNR: 10.9631, SSIM: 0.1231, LPIPS: 0.7672\n",
            "Sample [30/1141], PSNR: 11.0991, SSIM: 0.1198, LPIPS: 0.7613\n",
            "Sample [31/1141], PSNR: 11.2269, SSIM: 0.0953, LPIPS: 0.7177\n",
            "Sample [32/1141], PSNR: 10.2170, SSIM: 0.0876, LPIPS: 0.7222\n",
            "Sample [33/1141], PSNR: 10.6516, SSIM: 0.0856, LPIPS: 0.7496\n",
            "Sample [34/1141], PSNR: 10.4566, SSIM: 0.0952, LPIPS: 0.7148\n",
            "Sample [35/1141], PSNR: 9.0282, SSIM: 0.0310, LPIPS: 0.7749\n",
            "Sample [36/1141], PSNR: 9.0272, SSIM: 0.0320, LPIPS: 0.7619\n",
            "Sample [37/1141], PSNR: 9.1068, SSIM: 0.0317, LPIPS: 0.7751\n",
            "Sample [38/1141], PSNR: 10.4622, SSIM: 0.0926, LPIPS: 0.7156\n",
            "Sample [39/1141], PSNR: 10.2838, SSIM: 0.0964, LPIPS: 0.7033\n",
            "Sample [40/1141], PSNR: 10.2134, SSIM: 0.0885, LPIPS: 0.7252\n",
            "Sample [41/1141], PSNR: 10.1251, SSIM: 0.0862, LPIPS: 0.7449\n",
            "Sample [42/1141], PSNR: 9.0838, SSIM: 0.0314, LPIPS: 0.7884\n",
            "Sample [43/1141], PSNR: 12.9608, SSIM: 0.1685, LPIPS: 0.7692\n",
            "Sample [44/1141], PSNR: 10.4895, SSIM: 0.0847, LPIPS: 0.7765\n",
            "Sample [45/1141], PSNR: 10.2273, SSIM: 0.0919, LPIPS: 0.7767\n",
            "Sample [46/1141], PSNR: 10.7044, SSIM: 0.0966, LPIPS: 0.7656\n",
            "Sample [47/1141], PSNR: 10.8068, SSIM: 0.0989, LPIPS: 0.7278\n",
            "Sample [48/1141], PSNR: 9.5316, SSIM: 0.0562, LPIPS: 0.7583\n",
            "Sample [49/1141], PSNR: 11.0507, SSIM: 0.1167, LPIPS: 0.7796\n",
            "Sample [50/1141], PSNR: 10.5913, SSIM: 0.1067, LPIPS: 0.7708\n",
            "Sample [51/1141], PSNR: 13.6172, SSIM: 0.1049, LPIPS: 0.7475\n",
            "Sample [52/1141], PSNR: 10.9794, SSIM: 0.1383, LPIPS: 0.7629\n",
            "Sample [53/1141], PSNR: 10.7737, SSIM: 0.1467, LPIPS: 0.7867\n",
            "Sample [54/1141], PSNR: 7.6631, SSIM: 0.1651, LPIPS: 0.8090\n",
            "Sample [55/1141], PSNR: 6.4650, SSIM: 0.1462, LPIPS: 0.8647\n",
            "Sample [56/1141], PSNR: 5.6541, SSIM: 0.1525, LPIPS: 0.9133\n",
            "Sample [57/1141], PSNR: 7.0865, SSIM: 0.1632, LPIPS: 0.8124\n",
            "Sample [58/1141], PSNR: 5.8329, SSIM: 0.1521, LPIPS: 0.8745\n",
            "Sample [59/1141], PSNR: 12.0785, SSIM: 0.1312, LPIPS: 0.7490\n",
            "Sample [60/1141], PSNR: 14.0404, SSIM: 0.1085, LPIPS: 0.7468\n",
            "Sample [61/1141], PSNR: 12.8534, SSIM: 0.1524, LPIPS: 0.7634\n",
            "Sample [62/1141], PSNR: 10.6836, SSIM: 0.1083, LPIPS: 0.7698\n",
            "Sample [63/1141], PSNR: 10.3095, SSIM: 0.0861, LPIPS: 0.7824\n",
            "Sample [64/1141], PSNR: 13.8189, SSIM: 0.1732, LPIPS: 0.7923\n",
            "Sample [65/1141], PSNR: 15.2508, SSIM: 0.1966, LPIPS: 0.7662\n",
            "Sample [66/1141], PSNR: 13.7979, SSIM: 0.1743, LPIPS: 0.7761\n",
            "Sample [67/1141], PSNR: 12.6617, SSIM: 0.1367, LPIPS: 0.7814\n",
            "Sample [68/1141], PSNR: 12.7287, SSIM: 0.1653, LPIPS: 0.7764\n",
            "Sample [69/1141], PSNR: 11.4185, SSIM: 0.1309, LPIPS: 0.7785\n",
            "Sample [70/1141], PSNR: 13.5454, SSIM: 0.1735, LPIPS: 0.7770\n",
            "Sample [71/1141], PSNR: 10.3981, SSIM: 0.1213, LPIPS: 0.7385\n",
            "Sample [72/1141], PSNR: 10.6327, SSIM: 0.1239, LPIPS: 0.7183\n",
            "Sample [73/1141], PSNR: 8.5339, SSIM: 0.0112, LPIPS: 0.7606\n",
            "Sample [74/1141], PSNR: 8.5925, SSIM: 0.0122, LPIPS: 0.7466\n",
            "Sample [75/1141], PSNR: 8.8494, SSIM: 0.0274, LPIPS: 0.7774\n",
            "Sample [76/1141], PSNR: 8.0984, SSIM: 0.1148, LPIPS: 0.7778\n",
            "Sample [77/1141], PSNR: 7.2921, SSIM: 0.1306, LPIPS: 0.8107\n",
            "Sample [78/1141], PSNR: 9.1358, SSIM: 0.0377, LPIPS: 0.7711\n",
            "Sample [79/1141], PSNR: 9.8163, SSIM: 0.1297, LPIPS: 0.7544\n",
            "Sample [80/1141], PSNR: 9.0762, SSIM: 0.1330, LPIPS: 0.7636\n",
            "Sample [81/1141], PSNR: 9.3636, SSIM: 0.0587, LPIPS: 0.8263\n",
            "Sample [82/1141], PSNR: 10.1520, SSIM: 0.0960, LPIPS: 0.8177\n",
            "Sample [83/1141], PSNR: 9.1700, SSIM: 0.0470, LPIPS: 0.7512\n",
            "Sample [84/1141], PSNR: 9.7026, SSIM: 0.0657, LPIPS: 0.7762\n",
            "Sample [85/1141], PSNR: 9.5365, SSIM: 0.0583, LPIPS: 0.7952\n",
            "Sample [86/1141], PSNR: 10.5354, SSIM: 0.1079, LPIPS: 0.7943\n",
            "Sample [87/1141], PSNR: 9.0306, SSIM: 0.0385, LPIPS: 0.7945\n",
            "Sample [88/1141], PSNR: 9.2511, SSIM: 0.0470, LPIPS: 0.7953\n",
            "Sample [89/1141], PSNR: 10.1109, SSIM: 0.0910, LPIPS: 0.7868\n",
            "Sample [90/1141], PSNR: 9.5599, SSIM: 0.0639, LPIPS: 0.7433\n",
            "Sample [91/1141], PSNR: 9.4332, SSIM: 0.0599, LPIPS: 0.8046\n",
            "Sample [92/1141], PSNR: 10.7328, SSIM: 0.1061, LPIPS: 0.7470\n",
            "Sample [93/1141], PSNR: 11.6483, SSIM: 0.1524, LPIPS: 0.7215\n",
            "Sample [94/1141], PSNR: 7.9839, SSIM: 0.1148, LPIPS: 0.7607\n",
            "Sample [95/1141], PSNR: 11.0340, SSIM: 0.1026, LPIPS: 0.7389\n",
            "Sample [96/1141], PSNR: 10.6237, SSIM: 0.0936, LPIPS: 0.7184\n",
            "Sample [97/1141], PSNR: 10.4141, SSIM: 0.1215, LPIPS: 0.7578\n",
            "Sample [98/1141], PSNR: 11.6249, SSIM: 0.0969, LPIPS: 0.7482\n",
            "Sample [99/1141], PSNR: 10.3258, SSIM: 0.1333, LPIPS: 0.7573\n",
            "Sample [100/1141], PSNR: 10.5289, SSIM: 0.0959, LPIPS: 0.7315\n",
            "Sample [101/1141], PSNR: 10.2694, SSIM: 0.0882, LPIPS: 0.7249\n",
            "Sample [102/1141], PSNR: 12.1006, SSIM: 0.1416, LPIPS: 0.8504\n",
            "Sample [103/1141], PSNR: 13.1080, SSIM: 0.1731, LPIPS: 0.8901\n",
            "Sample [104/1141], PSNR: 12.8340, SSIM: 0.1714, LPIPS: 0.8691\n",
            "Sample [105/1141], PSNR: 11.3382, SSIM: 0.1321, LPIPS: 0.8623\n",
            "Sample [106/1141], PSNR: 11.7250, SSIM: 0.1643, LPIPS: 0.8828\n",
            "Sample [107/1141], PSNR: 9.5328, SSIM: 0.1562, LPIPS: 0.8746\n",
            "Sample [108/1141], PSNR: 12.3303, SSIM: 0.1534, LPIPS: 0.8531\n",
            "Sample [109/1141], PSNR: 10.2604, SSIM: 0.1443, LPIPS: 0.8531\n",
            "Sample [110/1141], PSNR: 12.4712, SSIM: 0.1624, LPIPS: 0.8861\n",
            "Sample [111/1141], PSNR: 12.0167, SSIM: 0.1488, LPIPS: 0.8624\n",
            "Sample [112/1141], PSNR: 11.0677, SSIM: 0.1170, LPIPS: 0.8503\n",
            "Sample [113/1141], PSNR: 5.6690, SSIM: 0.1550, LPIPS: 0.9091\n",
            "Sample [114/1141], PSNR: 12.0541, SSIM: 0.1508, LPIPS: 0.7499\n",
            "Sample [115/1141], PSNR: 8.7025, SSIM: 0.0838, LPIPS: 0.7626\n",
            "Sample [116/1141], PSNR: 9.9307, SSIM: 0.0767, LPIPS: 0.7614\n",
            "Sample [117/1141], PSNR: 5.4641, SSIM: 0.1472, LPIPS: 0.8832\n",
            "Sample [118/1141], PSNR: 5.7040, SSIM: 0.1527, LPIPS: 0.9125\n",
            "Sample [119/1141], PSNR: 9.2802, SSIM: 0.1001, LPIPS: 0.7898\n",
            "Sample [120/1141], PSNR: 8.6083, SSIM: 0.0800, LPIPS: 0.7758\n",
            "Sample [121/1141], PSNR: 10.2119, SSIM: 0.0928, LPIPS: 0.7023\n",
            "Sample [122/1141], PSNR: 12.6975, SSIM: 0.1423, LPIPS: 0.7739\n",
            "Sample [123/1141], PSNR: 14.1293, SSIM: 0.1805, LPIPS: 0.7608\n",
            "Sample [124/1141], PSNR: 10.4607, SSIM: 0.1055, LPIPS: 0.7892\n",
            "Sample [125/1141], PSNR: 7.7702, SSIM: 0.1877, LPIPS: 0.8543\n",
            "Sample [126/1141], PSNR: 10.8980, SSIM: 0.1711, LPIPS: 0.8009\n",
            "Sample [127/1141], PSNR: 8.3722, SSIM: 0.1429, LPIPS: 0.7812\n",
            "Sample [128/1141], PSNR: 10.4666, SSIM: 0.1374, LPIPS: 0.7871\n",
            "Sample [129/1141], PSNR: 13.4636, SSIM: 0.1838, LPIPS: 0.7885\n",
            "Sample [130/1141], PSNR: 7.0779, SSIM: 0.1803, LPIPS: 0.8197\n",
            "Sample [131/1141], PSNR: 5.3542, SSIM: 0.1655, LPIPS: 0.9093\n",
            "Sample [132/1141], PSNR: 9.5222, SSIM: 0.1274, LPIPS: 0.8255\n",
            "Sample [133/1141], PSNR: 9.5518, SSIM: 0.1243, LPIPS: 0.7806\n",
            "Sample [134/1141], PSNR: 9.3536, SSIM: 0.1771, LPIPS: 0.7711\n",
            "Sample [135/1141], PSNR: 5.9220, SSIM: 0.1573, LPIPS: 0.7623\n",
            "Sample [136/1141], PSNR: 11.0518, SSIM: 0.1449, LPIPS: 0.7761\n",
            "Sample [137/1141], PSNR: 8.8700, SSIM: 0.1506, LPIPS: 0.7794\n",
            "Sample [138/1141], PSNR: 8.2319, SSIM: 0.1690, LPIPS: 0.7760\n",
            "Sample [139/1141], PSNR: 7.8281, SSIM: 0.1720, LPIPS: 0.7645\n",
            "Sample [140/1141], PSNR: 10.6163, SSIM: 0.1912, LPIPS: 0.7929\n",
            "Sample [141/1141], PSNR: 9.9805, SSIM: 0.1686, LPIPS: 0.7908\n",
            "Sample [142/1141], PSNR: 9.2480, SSIM: 0.1350, LPIPS: 0.7709\n",
            "Sample [143/1141], PSNR: 6.0835, SSIM: 0.1488, LPIPS: 0.7602\n",
            "Sample [144/1141], PSNR: 10.0118, SSIM: 0.0815, LPIPS: 0.7792\n",
            "Sample [145/1141], PSNR: 11.8387, SSIM: 0.1446, LPIPS: 0.8005\n",
            "Sample [146/1141], PSNR: 12.6995, SSIM: 0.1667, LPIPS: 0.7662\n",
            "Sample [147/1141], PSNR: 12.7499, SSIM: 0.1790, LPIPS: 0.8006\n",
            "Sample [148/1141], PSNR: 10.5935, SSIM: 0.1028, LPIPS: 0.7919\n",
            "Sample [149/1141], PSNR: 11.1874, SSIM: 0.1288, LPIPS: 0.8048\n",
            "Sample [150/1141], PSNR: 12.9435, SSIM: 0.1684, LPIPS: 0.7961\n",
            "Sample [151/1141], PSNR: 11.6453, SSIM: 0.1697, LPIPS: 0.7710\n",
            "Sample [152/1141], PSNR: 11.5812, SSIM: 0.1350, LPIPS: 0.7667\n",
            "Sample [153/1141], PSNR: 11.8356, SSIM: 0.1450, LPIPS: 0.8083\n",
            "Sample [154/1141], PSNR: 10.5868, SSIM: 0.1090, LPIPS: 0.7535\n",
            "Sample [155/1141], PSNR: 10.7740, SSIM: 0.1072, LPIPS: 0.7691\n",
            "Sample [156/1141], PSNR: 6.4332, SSIM: 0.1280, LPIPS: 0.7338\n",
            "Sample [157/1141], PSNR: 11.5305, SSIM: 0.1071, LPIPS: 0.7204\n",
            "Sample [158/1141], PSNR: 9.3800, SSIM: 0.0478, LPIPS: 0.7064\n",
            "Sample [159/1141], PSNR: 8.9236, SSIM: 0.0291, LPIPS: 0.6841\n",
            "Sample [160/1141], PSNR: 8.3482, SSIM: 0.0867, LPIPS: 0.6969\n",
            "Sample [161/1141], PSNR: 11.0372, SSIM: 0.1107, LPIPS: 0.6451\n",
            "Sample [162/1141], PSNR: 9.0216, SSIM: 0.1198, LPIPS: 0.7285\n",
            "Sample [163/1141], PSNR: 8.9260, SSIM: 0.1391, LPIPS: 0.7568\n",
            "Sample [164/1141], PSNR: 9.8647, SSIM: 0.1204, LPIPS: 0.7714\n",
            "Sample [165/1141], PSNR: 10.1543, SSIM: 0.0867, LPIPS: 0.7136\n",
            "Sample [166/1141], PSNR: 12.0570, SSIM: 0.1737, LPIPS: 0.7928\n",
            "Sample [167/1141], PSNR: 13.3634, SSIM: 0.1767, LPIPS: 0.7710\n",
            "Sample [168/1141], PSNR: 10.0405, SSIM: 0.0878, LPIPS: 0.7026\n",
            "Sample [169/1141], PSNR: 12.1227, SSIM: 0.1554, LPIPS: 0.6823\n",
            "Sample [170/1141], PSNR: 9.2749, SSIM: 0.1270, LPIPS: 0.7422\n",
            "Sample [171/1141], PSNR: 11.7170, SSIM: 0.1120, LPIPS: 0.7411\n",
            "Sample [172/1141], PSNR: 10.7942, SSIM: 0.1171, LPIPS: 0.7849\n",
            "Sample [173/1141], PSNR: 8.9997, SSIM: 0.0296, LPIPS: 0.7598\n",
            "Sample [174/1141], PSNR: 12.1301, SSIM: 0.1106, LPIPS: 0.7126\n",
            "Sample [175/1141], PSNR: 9.5318, SSIM: 0.0522, LPIPS: 0.7240\n",
            "Sample [176/1141], PSNR: 10.5766, SSIM: 0.1118, LPIPS: 0.7609\n",
            "Sample [177/1141], PSNR: 5.3258, SSIM: 0.1728, LPIPS: 0.9203\n",
            "Sample [178/1141], PSNR: 9.5220, SSIM: 0.0634, LPIPS: 0.7947\n",
            "Sample [179/1141], PSNR: 9.2621, SSIM: 0.1540, LPIPS: 0.8205\n",
            "Sample [180/1141], PSNR: 8.1660, SSIM: 0.1146, LPIPS: 0.8612\n",
            "Sample [181/1141], PSNR: 8.0651, SSIM: 0.1528, LPIPS: 0.8452\n",
            "Sample [182/1141], PSNR: 16.4525, SSIM: 0.2132, LPIPS: 0.7596\n",
            "Sample [183/1141], PSNR: 9.2983, SSIM: 0.0535, LPIPS: 0.8073\n",
            "Sample [184/1141], PSNR: 8.8688, SSIM: 0.0293, LPIPS: 0.6190\n",
            "Sample [185/1141], PSNR: 13.7079, SSIM: 0.1594, LPIPS: 0.6370\n",
            "Sample [186/1141], PSNR: 10.4543, SSIM: 0.0808, LPIPS: 0.7308\n",
            "Sample [187/1141], PSNR: 10.4230, SSIM: 0.1031, LPIPS: 0.7921\n",
            "Sample [188/1141], PSNR: 11.9118, SSIM: 0.1486, LPIPS: 0.7280\n",
            "Sample [189/1141], PSNR: 10.5591, SSIM: 0.0958, LPIPS: 0.7513\n",
            "Sample [190/1141], PSNR: 11.9095, SSIM: 0.1175, LPIPS: 0.7399\n",
            "Sample [191/1141], PSNR: 7.1938, SSIM: 0.1572, LPIPS: 0.6856\n",
            "Sample [192/1141], PSNR: 12.0857, SSIM: 0.1218, LPIPS: 0.7215\n",
            "Sample [193/1141], PSNR: 6.5674, SSIM: 0.1396, LPIPS: 0.8221\n",
            "Sample [194/1141], PSNR: 9.1147, SSIM: 0.0411, LPIPS: 0.7685\n",
            "Sample [195/1141], PSNR: 8.3849, SSIM: 0.1184, LPIPS: 0.7517\n",
            "Sample [196/1141], PSNR: 10.4972, SSIM: 0.1475, LPIPS: 0.7318\n",
            "Sample [197/1141], PSNR: 5.5623, SSIM: 0.1473, LPIPS: 0.9193\n",
            "Sample [198/1141], PSNR: 10.3893, SSIM: 0.0979, LPIPS: 0.8549\n",
            "Sample [199/1141], PSNR: 11.4817, SSIM: 0.1300, LPIPS: 0.7683\n",
            "Sample [200/1141], PSNR: 11.2251, SSIM: 0.1396, LPIPS: 0.7492\n",
            "Sample [201/1141], PSNR: 8.8550, SSIM: 0.0198, LPIPS: 0.7971\n",
            "Sample [202/1141], PSNR: 11.0554, SSIM: 0.0983, LPIPS: 0.6973\n",
            "Sample [203/1141], PSNR: 7.7071, SSIM: 0.1301, LPIPS: 0.7847\n",
            "Sample [204/1141], PSNR: 8.1862, SSIM: 0.1054, LPIPS: 0.7799\n",
            "Sample [205/1141], PSNR: 11.3320, SSIM: 0.1202, LPIPS: 0.7390\n",
            "Sample [206/1141], PSNR: 8.5904, SSIM: 0.0653, LPIPS: 0.7639\n",
            "Sample [207/1141], PSNR: 11.6322, SSIM: 0.1307, LPIPS: 0.7756\n",
            "Sample [208/1141], PSNR: 12.0105, SSIM: 0.0742, LPIPS: 0.7256\n",
            "Sample [209/1141], PSNR: 11.1052, SSIM: 0.1142, LPIPS: 0.7506\n",
            "Sample [210/1141], PSNR: 10.8088, SSIM: 0.1570, LPIPS: 0.9251\n",
            "Sample [211/1141], PSNR: 10.7179, SSIM: 0.1803, LPIPS: 0.7783\n",
            "Sample [212/1141], PSNR: 11.4473, SSIM: 0.1235, LPIPS: 0.6764\n",
            "Sample [213/1141], PSNR: 9.0167, SSIM: 0.1650, LPIPS: 0.7917\n",
            "Sample [214/1141], PSNR: 12.2903, SSIM: 0.1302, LPIPS: 0.7714\n",
            "Sample [215/1141], PSNR: 8.4885, SSIM: 0.0076, LPIPS: 0.7695\n",
            "Sample [216/1141], PSNR: 13.7325, SSIM: 0.1686, LPIPS: 0.7673\n",
            "Sample [217/1141], PSNR: 9.6487, SSIM: 0.1372, LPIPS: 0.7864\n",
            "Sample [218/1141], PSNR: 5.4458, SSIM: 0.1682, LPIPS: 0.9360\n",
            "Sample [219/1141], PSNR: 11.6825, SSIM: 0.1368, LPIPS: 0.7758\n",
            "Sample [220/1141], PSNR: 9.6156, SSIM: 0.1238, LPIPS: 0.7398\n",
            "Sample [221/1141], PSNR: 7.7586, SSIM: 0.1525, LPIPS: 0.7592\n",
            "Sample [222/1141], PSNR: 10.3864, SSIM: 0.0989, LPIPS: 0.8399\n",
            "Sample [223/1141], PSNR: 13.9683, SSIM: 0.1818, LPIPS: 0.7825\n",
            "Sample [224/1141], PSNR: 10.5206, SSIM: 0.1078, LPIPS: 0.7673\n",
            "Sample [225/1141], PSNR: 11.1190, SSIM: 0.0794, LPIPS: 0.7158\n",
            "Sample [226/1141], PSNR: 9.5230, SSIM: 0.1554, LPIPS: 0.7831\n",
            "Sample [227/1141], PSNR: 12.4394, SSIM: 0.1723, LPIPS: 0.7864\n",
            "Sample [228/1141], PSNR: 9.6530, SSIM: 0.0648, LPIPS: 0.7431\n",
            "Sample [229/1141], PSNR: 11.2328, SSIM: 0.1143, LPIPS: 0.7451\n",
            "Sample [230/1141], PSNR: 10.9076, SSIM: 0.1029, LPIPS: 0.7122\n",
            "Sample [231/1141], PSNR: 8.6578, SSIM: 0.1367, LPIPS: 0.7949\n",
            "Sample [232/1141], PSNR: 10.1930, SSIM: 0.0775, LPIPS: 0.7278\n",
            "Sample [233/1141], PSNR: 8.4591, SSIM: 0.0074, LPIPS: 0.7725\n",
            "Sample [234/1141], PSNR: 12.4597, SSIM: 0.1344, LPIPS: 0.7619\n",
            "Sample [235/1141], PSNR: 10.3914, SSIM: 0.0979, LPIPS: 0.7568\n",
            "Sample [236/1141], PSNR: 11.0922, SSIM: 0.1108, LPIPS: 0.7667\n",
            "Sample [237/1141], PSNR: 15.4615, SSIM: 0.2068, LPIPS: 0.7476\n",
            "Sample [238/1141], PSNR: 9.5289, SSIM: 0.1445, LPIPS: 0.7844\n",
            "Sample [239/1141], PSNR: 10.6170, SSIM: 0.0855, LPIPS: 0.7380\n",
            "Sample [240/1141], PSNR: 9.8068, SSIM: 0.1189, LPIPS: 0.7053\n",
            "Sample [241/1141], PSNR: 11.0190, SSIM: 0.1591, LPIPS: 0.7984\n",
            "Sample [242/1141], PSNR: 8.0723, SSIM: 0.1295, LPIPS: 0.8443\n",
            "Sample [243/1141], PSNR: 5.6656, SSIM: 0.1513, LPIPS: 0.9234\n",
            "Sample [244/1141], PSNR: 8.9783, SSIM: 0.0351, LPIPS: 0.7943\n",
            "Sample [245/1141], PSNR: 11.2122, SSIM: 0.1530, LPIPS: 0.8461\n",
            "Sample [246/1141], PSNR: 6.8646, SSIM: 0.1289, LPIPS: 0.8760\n",
            "Sample [247/1141], PSNR: 11.9159, SSIM: 0.1470, LPIPS: 0.7786\n",
            "Sample [248/1141], PSNR: 12.0450, SSIM: 0.1306, LPIPS: 0.7551\n",
            "Sample [249/1141], PSNR: 6.8844, SSIM: 0.1578, LPIPS: 0.7901\n",
            "Sample [250/1141], PSNR: 13.6242, SSIM: 0.1845, LPIPS: 0.7895\n",
            "Sample [251/1141], PSNR: 13.4439, SSIM: 0.1682, LPIPS: 0.7637\n",
            "Sample [252/1141], PSNR: 12.3496, SSIM: 0.1766, LPIPS: 0.8569\n",
            "Sample [253/1141], PSNR: 9.4695, SSIM: 0.0437, LPIPS: 0.7271\n",
            "Sample [254/1141], PSNR: 10.7179, SSIM: 0.0935, LPIPS: 0.7245\n",
            "Sample [255/1141], PSNR: 10.4322, SSIM: 0.0959, LPIPS: 0.8111\n",
            "Sample [256/1141], PSNR: 11.6779, SSIM: 0.1349, LPIPS: 0.7870\n",
            "Sample [257/1141], PSNR: 10.0968, SSIM: 0.0928, LPIPS: 0.7501\n",
            "Sample [258/1141], PSNR: 10.2776, SSIM: 0.0908, LPIPS: 0.7594\n",
            "Sample [259/1141], PSNR: 12.9814, SSIM: 0.1211, LPIPS: 0.6796\n",
            "Sample [260/1141], PSNR: 9.4799, SSIM: 0.0599, LPIPS: 0.7672\n",
            "Sample [261/1141], PSNR: 8.9491, SSIM: 0.0297, LPIPS: 0.6705\n",
            "Sample [262/1141], PSNR: 9.1557, SSIM: 0.0448, LPIPS: 0.7916\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-9-4fbae87a479d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0m__name__\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"__main__\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 122\u001b[0;31m     \u001b[0mtest_diffusion_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m<ipython-input-9-4fbae87a479d>\u001b[0m in \u001b[0;36mtest_diffusion_model\u001b[0;34m()\u001b[0m\n\u001b[1;32m     70\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     71\u001b[0m                     \u001b[0;31m# Predict noise\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 72\u001b[0;31m                     \u001b[0mpredicted_noise\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_t\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     73\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     74\u001b[0m                     \u001b[0;31m# Compute coefficients\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-3-5441054c086d>\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmiddle\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    252\u001b[0m             \u001b[0mm\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mblock\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 253\u001b[0;31m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mup1\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    254\u001b[0m         \u001b[0md1\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0md1\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0me4\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    255\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mblock\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdec1\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1737\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_compiled_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# type: ignore[misc]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1738\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1739\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call_impl\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1740\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1741\u001b[0m     \u001b[0;31m# torchrec tests the code consistency with the following code\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/module.py\u001b[0m in \u001b[0;36m_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1748\u001b[0m                 \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_pre_hooks\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_global_backward_hooks\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1749\u001b[0m                 or _global_forward_hooks or _global_forward_pre_hooks):\n\u001b[0;32m-> 1750\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mforward_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1751\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1752\u001b[0m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/nn/modules/conv.py\u001b[0m in \u001b[0;36mforward\u001b[0;34m(self, input, output_size)\u001b[0m\n\u001b[1;32m   1160\u001b[0m         )\n\u001b[1;32m   1161\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1162\u001b[0;31m         return F.conv_transpose2d(\n\u001b[0m\u001b[1;32m   1163\u001b[0m             \u001b[0minput\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mweight\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "import rawpy\n",
        "import torch\n",
        "from torch.utils.data import Dataset, DataLoader\n",
        "import torchmetrics\n",
        "from torchmetrics.image import PeakSignalNoiseRatio, StructuralSimilarityIndexMeasure\n",
        "from torchmetrics.image.lpip import LearnedPerceptualImagePatchSimilarity\n",
        "\n",
        "# Clear GPU memory\n",
        "torch.cuda.empty_cache()\n",
        "\n",
        "# Custom Dataset for SID (×100 amplification, limited to 20 images)\n",
        "class SIDDataset(Dataset):\n",
        "    def __init__(self, txt_file, data_root='/content/aml-sld', patch_size=256, target_amplification=100, max_images=20):\n",
        "        self.data_root = data_root\n",
        "        self.patch_size = patch_size\n",
        "        self.target_amplification = target_amplification\n",
        "        self.max_images = max_images\n",
        "        self.pairs = []\n",
        "\n",
        "        # Load pairs from the .txt file\n",
        "        with open(txt_file, 'r') as f:\n",
        "            lines = f.readlines()\n",
        "            for line in lines:\n",
        "                short_path, long_path, iso, fstop = line.strip().split()\n",
        "                short_exp = float(short_path.split('_')[-1].replace('s.ARW', ''))\n",
        "                long_exp = float(long_path.split('_')[-1].replace('s.ARW', ''))\n",
        "                if short_exp > 0:\n",
        "                    amplification = long_exp / short_exp\n",
        "                    if 90 <= amplification <= 110:\n",
        "                        self.pairs.append((short_path, long_path, short_exp, long_exp))\n",
        "                        if len(self.pairs) >= self.max_images:\n",
        "                            break\n",
        "\n",
        "        print(f\"Test dataset: Selected {len(self.pairs)} pairs with amplification ratio ~{target_amplification}\")\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.pairs)\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "        short_path, long_path, short_exp, long_exp = self.pairs[idx]\n",
        "\n",
        "        # Load raw images\n",
        "        short_raw = rawpy.imread(os.path.join(self.data_root, short_path))\n",
        "        long_raw = rawpy.imread(os.path.join(self.data_root, long_path))\n",
        "\n",
        "        short_bayer = short_raw.raw_image_visible.astype(np.float32) - 512\n",
        "        long_bayer = long_raw.raw_image_visible.astype(np.float32) - 512\n",
        "\n",
        "        short_bayer = np.clip(short_bayer / (4095 - 512), 0, 1)\n",
        "        long_bayer = np.clip(long_bayer / (4095 - 512), 0, 1)\n",
        "\n",
        "        h, w = short_bayer.shape\n",
        "        short_packed = np.zeros((h//2, w//2, 4), dtype=np.float32)\n",
        "        long_packed = np.zeros((h//2, w//2, 4), dtype=np.float32)\n",
        "\n",
        "        short_packed[..., 0] = short_bayer[0::2, 0::2]\n",
        "        short_packed[..., 1] = short_bayer[0::2, 1::2]\n",
        "        short_packed[..., 2] = short_bayer[1::2, 0::2]\n",
        "        short_packed[..., 3] = short_bayer[1::2, 1::2]\n",
        "        long_packed[..., 0] = long_bayer[0::2, 0::2]\n",
        "        long_packed[..., 1] = long_bayer[0::2, 1::2]\n",
        "        long_packed[..., 2] = long_bayer[1::2, 0::2]\n",
        "        long_packed[..., 3] = long_bayer[1::2, 1::2]\n",
        "\n",
        "        # Center crop for testing\n",
        "        h, w, _ = short_packed.shape\n",
        "        i = (h - self.patch_size) // 2\n",
        "        j = (w - self.patch_size) // 2\n",
        "        short_patch = short_packed[i:i+self.patch_size, j:j+self.patch_size, :]\n",
        "        long_patch = long_packed[i:i+self.patch_size, j:j+self.patch_size, :]\n",
        "\n",
        "        short_patch = torch.from_numpy(short_patch).permute(2, 0, 1)\n",
        "        long_patch = torch.from_numpy(long_patch).permute(2, 0, 1)\n",
        "\n",
        "        return short_path, short_patch, long_patch, short_exp, long_exp\n",
        "\n",
        "# Helper function to convert 4-channel Bayer-packed data to 3-channel RGB-like data\n",
        "def bayer_to_rgb(bayer_tensor):\n",
        "    r = bayer_tensor[:, 0:1, :, :]\n",
        "    g = (bayer_tensor[:, 1:2, :, :] + bayer_tensor[:, 2:3, :, :]) / 2\n",
        "    b = bayer_tensor[:, 3:4, :, :]\n",
        "    rgb_tensor = torch.cat([r, g, b], dim=1)\n",
        "    return rgb_tensor\n",
        "\n",
        "# Test Function for Diffusion Model (20 images)\n",
        "def test_diffusion_model():\n",
        "    data_root = \"/content/aml-sld\"\n",
        "    test_txt = os.path.join(data_root, \"Sony_test_list.txt\")\n",
        "    metrics_file = \"/content/test_metrics.txt\"\n",
        "\n",
        "    test_dataset = SIDDataset(test_txt, data_root=data_root, patch_size=256, target_amplification=100, max_images=20)\n",
        "    test_loader = DataLoader(test_dataset, batch_size=1, shuffle=False, num_workers=2, pin_memory=True)\n",
        "\n",
        "    device = torch.device(\"cuda:0\" if torch.cuda.is_available() else \"cpu\")\n",
        "    if not torch.cuda.is_available():\n",
        "        raise RuntimeError(\"GPU not available\")\n",
        "    print(f\"Using device: {device}\")\n",
        "\n",
        "    model = NAFNet(in_channels=4, out_channels=4, width=32, enc_blocks=[2, 2, 2, 2], dec_blocks=[2, 2, 2, 2], middle_blocks=2, drop_path_rate=0.0).to(device)\n",
        "    model.load_state_dict(torch.load(\"/content/diffusion_model.pth\", weights_only=True))\n",
        "    model.eval()\n",
        "\n",
        "    # Initialize metrics\n",
        "    psnr_metric = PeakSignalNoiseRatio(data_range=1.0).to(device)\n",
        "    ssim_metric = StructuralSimilarityIndexMeasure(data_range=1.0).to(device)\n",
        "    lpips_metric = LearnedPerceptualImagePatchSimilarity(net_type='vgg', normalize=True).to(device)\n",
        "\n",
        "    # Diffusion parameters (same as training)\n",
        "    num_timesteps = 1000\n",
        "    beta_start = 0.0001\n",
        "    beta_end = 0.02\n",
        "    betas = torch.linspace(beta_start, beta_end, num_timesteps, device=device)\n",
        "    alphas = 1.0 - betas\n",
        "    alphas_cumprod = torch.cumprod(alphas, dim=0)\n",
        "    sqrt_alphas_cumprod = torch.sqrt(alphas_cumprod)\n",
        "    sqrt_one_minus_alphas_cumprod = torch.sqrt(1.0 - alphas_cumprod)\n",
        "    alpha_bar_t = alphas_cumprod\n",
        "    one_minus_alpha_bar_t = 1.0 - alphas_cumprod\n",
        "    sqrt_one_minus_alpha_bar_t = torch.sqrt(one_minus_alpha_bar_t)\n",
        "\n",
        "    total_psnr, total_ssim, total_lpips = 0.0, 0.0, 0.0\n",
        "    num_samples = 0\n",
        "    metrics_list = []\n",
        "\n",
        "    print(\"Starting diffusion model testing on 20 images...\")\n",
        "    with torch.no_grad():\n",
        "        for i, (short_path, short_img, long_img, _, _) in enumerate(test_loader):\n",
        "            short_img = short_img.to(device, non_blocking=True)\n",
        "            long_img = long_img.to(device, non_blocking=True)\n",
        "            short_path = short_path[0]  # Extract string from tuple\n",
        "\n",
        "            # Initialize with pure noise (simulate x_T)\n",
        "            x_t = torch.randn_like(long_img)\n",
        "\n",
        "            # Reverse diffusion process\n",
        "            for t in range(num_timesteps - 1, -1, -1):\n",
        "                t_tensor = torch.full((1,), t, device=device, dtype=torch.long)\n",
        "\n",
        "                # Predict noise\n",
        "                predicted_noise = model(x_t)\n",
        "\n",
        "                # Compute coefficients\n",
        "                alpha_t = alphas[t]\n",
        "                alpha_bar_t_val = alpha_bar_t[t]\n",
        "                sqrt_one_minus_alpha_bar_t_val = sqrt_one_minus_alpha_bar_t[t]\n",
        "\n",
        "                # Denoise step\n",
        "                noise = torch.randn_like(x_t) if t > 0 else torch.zeros_like(x_t)\n",
        "                x_t = (1.0 / torch.sqrt(alpha_t)) * (x_t - ((1 - alpha_t) / sqrt_one_minus_alpha_bar_t_val) * predicted_noise) + torch.sqrt(1 - alpha_t) * noise\n",
        "                x_t = torch.clamp(x_t, 0, 1)\n",
        "\n",
        "            # Final denoised image\n",
        "            pred_x0 = x_t\n",
        "\n",
        "            # Convert to RGB-like for LPIPS\n",
        "            pred_x0_rgb = bayer_to_rgb(pred_x0)\n",
        "            long_img_rgb = bayer_to_rgb(long_img)\n",
        "\n",
        "            # Compute metrics\n",
        "            psnr = psnr_metric(pred_x0, long_img)\n",
        "            ssim = ssim_metric(pred_x0, long_img)\n",
        "            lpips = lpips_metric(pred_x0_rgb, long_img_rgb)\n",
        "\n",
        "            total_psnr += psnr.item()\n",
        "            total_ssim += ssim.item()\n",
        "            total_lpips += lpips.item()\n",
        "            num_samples += 1\n",
        "\n",
        "            # Store metrics with image name\n",
        "            metrics_list.append((short_path, psnr.item(), ssim.item(), lpips.item()))\n",
        "\n",
        "            print(f\"Sample [{i+1}/{len(test_loader)}], Image: {os.path.basename(short_path)}, PSNR: {psnr:.4f}, SSIM: {ssim:.4f}, LPIPS: {lpips:.4f}\")\n",
        "\n",
        "    # Compute average metrics\n",
        "    avg_psnr = total_psnr / num_samples\n",
        "    avg_ssim = total_ssim / num_samples\n",
        "    avg_lpips = total_lpips / num_samples\n",
        "\n",
        "    # Save metrics to text file\n",
        "    with open(metrics_file, 'w') as f:\n",
        "        f.write(\"Diffusion Model Test Metrics (20 Images)\\n\")\n",
        "        f.write(\"-\" * 50 + \"\\n\")\n",
        "        f.write(\"Sample Metrics:\\n\")\n",
        "        for short_path, psnr, ssim, lpips in metrics_list:\n",
        "            f.write(f\"Image: {os.path.basename(short_path)}\\n\")\n",
        "            f.write(f\"PSNR: {psnr:.4f}\\n\")\n",
        "            f.write(f\"SSIM: {ssim:.4f}\\n\")\n",
        "            f.write(f\"LPIPS: {lpips:.4f}\\n\")\n",
        "            f.write(\"-\" * 50 + \"\\n\")\n",
        "        f.write(\"Average Metrics:\\n\")\n",
        "        f.write(f\"Average PSNR: {avg_psnr:.4f}\\n\")\n",
        "        f.write(f\"Average SSIM: {avg_ssim:.4f}\\n\")\n",
        "        f.write(f\"Average LPIPS: {avg_lpips:.4f}\\n\")\n",
        "\n",
        "    print(f\"\\nTest Results (saved to {metrics_file}):\")\n",
        "    print(f\"Average PSNR: {avg_psnr:.4f}\")\n",
        "    print(f\"Average SSIM: {avg_ssim:.4f}\")\n",
        "    print(f\"Average LPIPS: {avg_lpips:.4f}\")\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    test_diffusion_model()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WIJFGqKtaexf",
        "outputId": "51ac6364-9a39-49bc-8272-64683db263b1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test dataset: Selected 20 pairs with amplification ratio ~100\n",
            "Using device: cuda:0\n",
            "Starting diffusion model testing on 20 images...\n",
            "Sample [1/20], Image: 10003_00_0.1s.ARW, PSNR: 5.5281, SSIM: 0.0635, LPIPS: 0.7489\n",
            "Sample [2/20], Image: 10003_01_0.1s.ARW, PSNR: 5.5880, SSIM: 0.0633, LPIPS: 0.7553\n",
            "Sample [3/20], Image: 10003_02_0.1s.ARW, PSNR: 5.5704, SSIM: 0.0630, LPIPS: 0.7557\n",
            "Sample [4/20], Image: 10003_03_0.1s.ARW, PSNR: 5.5868, SSIM: 0.0630, LPIPS: 0.7526\n",
            "Sample [5/20], Image: 10003_04_0.1s.ARW, PSNR: 5.5557, SSIM: 0.0630, LPIPS: 0.7478\n",
            "Sample [6/20], Image: 10003_05_0.1s.ARW, PSNR: 5.5531, SSIM: 0.0623, LPIPS: 0.7474\n",
            "Sample [7/20], Image: 10003_06_0.1s.ARW, PSNR: 5.5501, SSIM: 0.0629, LPIPS: 0.7494\n",
            "Sample [8/20], Image: 10003_07_0.1s.ARW, PSNR: 5.5873, SSIM: 0.0639, LPIPS: 0.7521\n",
            "Sample [9/20], Image: 10003_08_0.1s.ARW, PSNR: 5.5712, SSIM: 0.0633, LPIPS: 0.7529\n",
            "Sample [10/20], Image: 10003_09_0.1s.ARW, PSNR: 5.5865, SSIM: 0.0647, LPIPS: 0.7531\n",
            "Sample [11/20], Image: 10006_00_0.1s.ARW, PSNR: 5.8684, SSIM: 0.0870, LPIPS: 0.7466\n",
            "Sample [12/20], Image: 10006_01_0.1s.ARW, PSNR: 5.8423, SSIM: 0.0874, LPIPS: 0.7436\n",
            "Sample [13/20], Image: 10006_02_0.1s.ARW, PSNR: 5.8452, SSIM: 0.0882, LPIPS: 0.7345\n",
            "Sample [14/20], Image: 10006_03_0.1s.ARW, PSNR: 5.8565, SSIM: 0.0883, LPIPS: 0.7432\n",
            "Sample [15/20], Image: 10006_04_0.1s.ARW, PSNR: 5.8566, SSIM: 0.0875, LPIPS: 0.7413\n",
            "Sample [16/20], Image: 10006_05_0.1s.ARW, PSNR: 5.8252, SSIM: 0.0886, LPIPS: 0.7447\n",
            "Sample [17/20], Image: 10006_06_0.1s.ARW, PSNR: 5.8529, SSIM: 0.0883, LPIPS: 0.7352\n",
            "Sample [18/20], Image: 10006_07_0.1s.ARW, PSNR: 5.8028, SSIM: 0.0874, LPIPS: 0.7390\n",
            "Sample [19/20], Image: 10006_08_0.1s.ARW, PSNR: 5.8243, SSIM: 0.0860, LPIPS: 0.7469\n",
            "Sample [20/20], Image: 10006_09_0.1s.ARW, PSNR: 5.8272, SSIM: 0.0854, LPIPS: 0.7492\n",
            "\n",
            "Test Results (saved to /content/test_metrics.txt):\n",
            "Average PSNR: 5.7039\n",
            "Average SSIM: 0.0753\n",
            "Average LPIPS: 0.7470\n"
          ]
        }
      ]
    }
  ]
}